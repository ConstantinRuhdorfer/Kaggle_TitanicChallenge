{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic Challenge using sklearns Random Forest Classifier\n",
    "\n",
    "This jupyter notebook will describe a model for Kaggle's \"Titanic: Machine Learning from Disaster\"-challenge (https://www.kaggle.com/c/titanic).\n",
    "\n",
    "You can get the data here: https://www.kaggle.com/c/titanic/data.\n",
    "\n",
    "## Libraries\n",
    "\n",
    "First we need to import some libraries.\n",
    "The libraries in question were used in the versions:\n",
    "\n",
    "1. Pandas 0.21.0\n",
    "2. Numpy 1.14.2\n",
    "3. sklearn 0.19.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "### Loading the data\n",
    "\n",
    "We first need to import the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training data\n",
    "data_labels = ['PassengerId','Survived','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked']\n",
    "data = pd.read_csv('./train.csv', skiprows=1, index_col=False, names=data_labels)\n",
    "\n",
    "# For the evualiation to be uploaded to kaggle\n",
    "predict_labels = ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
    "x_predict = pd.read_csv('./test.csv', skiprows=1, index_col=False, names= predict_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working the data\n",
    "\n",
    "We want to get relevant features from the dataset and therefore need to preprocess it.\n",
    "There were a few thinks which I wanted to consider for the model.\n",
    "\n",
    "#### Titles from names\n",
    "\n",
    "When you take a look at the data you will find that in the column 'Name' there is not only the full name included but also a title. I thought that a 'Major' might have a higher survival rate compared to a normaler 'Mr.' or 'Mrs.'. So I extract the title from every name in the dataset and - after adding the title to the model - dropped the name. I then converted this 'Title' column to a categorical one.\n",
    "But since not all of the Titles which can be found in the train set can be found in the prediction set I needed to make a big set in order to both have the same number of categories (even if that means that some columns in the prediction set will be filled by zeros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_title(dataset):\n",
    "    dataset['Name'] = dataset['Name'].str.split(', ', expand = True)[1]\n",
    "    dataset['Title'] = dataset['Name'].str.split(' ', expand = True)[0]\n",
    "    dataset = dataset.drop(['Name'], axis=1)\n",
    "    return dataset\n",
    "\n",
    "# The prediction set has no Survived column so we need to store it somewehere else will computing the titles.\n",
    "y_data = data['Survived']\n",
    "data = data.drop(['Survived'], axis=1)\n",
    "data = data.append(x_predict)\n",
    "\n",
    "data = retrieve_title(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values for age.\n",
    "\n",
    "data = data.fillna({\n",
    "    'Age': data['Age'].mean()\n",
    "})\n",
    "\n",
    "# There are just a few people with nan in Embarked so we can just drop them\n",
    "data = data.dropna(how='any', subset=['Embarked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummie categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dummies(dataset, column_list, _prefix):\n",
    "    return pd.get_dummies(dataset, columns=column_list, prefix=_prefix)\n",
    "\n",
    "data = make_dummies(data, ['Sex'], 'Sex')\n",
    "data = make_dummies(data, ['Embarked'], 'Embarked')\n",
    "data = make_dummies(data, ['Title'], 'Title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the prediction dataset again & Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train = data[:889]\n",
    "train['Survived'] = y_data\n",
    "x_predict = data[889:]\n",
    "\n",
    "x_train, x_test = train_test_split(train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the data here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Miss.</th>\n",
       "      <th>Title_Mlle.</th>\n",
       "      <th>Title_Mme.</th>\n",
       "      <th>Title_Mr.</th>\n",
       "      <th>Title_Mrs.</th>\n",
       "      <th>Title_Ms.</th>\n",
       "      <th>Title_Rev.</th>\n",
       "      <th>Title_Sir.</th>\n",
       "      <th>Title_the</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>715</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250647</td>\n",
       "      <td>13.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>717</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.525</td>\n",
       "      <td>C45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113806</td>\n",
       "      <td>53.100</td>\n",
       "      <td>E8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>683</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6563</td>\n",
       "      <td>9.225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35273</td>\n",
       "      <td>113.275</td>\n",
       "      <td>D36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass   Age  SibSp  Parch    Ticket     Fare Cabin  \\\n",
       "714          715       2  52.0      0      0    250647   13.000   NaN   \n",
       "716          717       1  38.0      0      0  PC 17757  227.525   C45   \n",
       "724          725       1  27.0      1      0    113806   53.100    E8   \n",
       "682          683       3  20.0      0      0      6563    9.225   NaN   \n",
       "215          216       1  31.0      1      0     35273  113.275   D36   \n",
       "\n",
       "     Sex_female  Sex_male    ...     Title_Miss.  Title_Mlle.  Title_Mme.  \\\n",
       "714           0         1    ...               0            0           0   \n",
       "716           1         0    ...               1            0           0   \n",
       "724           0         1    ...               0            0           0   \n",
       "682           0         1    ...               0            0           0   \n",
       "215           1         0    ...               1            0           0   \n",
       "\n",
       "     Title_Mr.  Title_Mrs.  Title_Ms.  Title_Rev.  Title_Sir.  Title_the  \\\n",
       "714          1           0          0           0           0          0   \n",
       "716          0           0          0           0           0          0   \n",
       "724          1           0          0           0           0          0   \n",
       "682          1           0          0           0           0          0   \n",
       "215          0           0          0           0           0          0   \n",
       "\n",
       "     Survived  \n",
       "714         0  \n",
       "716         1  \n",
       "724         1  \n",
       "682         0  \n",
       "215         1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = x_train['Survived']\n",
    "y_test = x_test['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop freatures we are not going to use\n",
    "x_train = x_train.drop(['PassengerId','Survived', 'Ticket', 'Fare', 'Cabin'], axis=1)\n",
    "x_test = x_test.drop(['PassengerId','Survived', 'Ticket', 'Fare', 'Cabin'], axis=1)\n",
    "x_predict = x_predict.drop(['PassengerId', 'Ticket', 'Fare', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "The training happens here.\n",
    "\n",
    "#### Hyperparameter-Tuning\n",
    "\n",
    "Hyperparameter tuning by hand often takes a lot of time and can be difficult and rather hard to understand.\n",
    "There are a number of ways when you want to automate hyperparameter tuning (Grid-Search, Bayesian Optimization, etc.) we are going to use Random Search in this project (for a detailed explaination on that start here http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be extra fancy\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 3000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 121, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10, 12, 15]\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier()\n",
    "\n",
    "clf_rad = RandomizedSearchCV(estimator = clf,\n",
    "                             param_distributions = random_grid,\n",
    "                             n_iter = 100,\n",
    "                             cv = 3,\n",
    "                             verbose=2,\n",
    "                             random_state=42,\n",
    "                             n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  5.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 511, 822, 1133, 1444, 1755, 2066, 2377, 2688, 3000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 21, 32, 43, 54, 65, 76, 87, 98, 109, 121, None], 'min_samples_split': [2, 5, 10, 12, 15], 'min_samples_leaf': [1, 2, 4, 6, 8], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rad.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 511, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 121, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# What should be used for training\n",
    "print(clf_rad.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "\n",
    "The model tries to label given every datapoint with an answer key it deems to be appropiate and compares it to the provided answer key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rad = clf_rad.best_estimator_\n",
    "y_pred=best_rad.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How well did we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.8663853727144867\n",
      "Test acc:  0.797752808988764\n"
     ]
    }
   ],
   "source": [
    "print('Train acc: ', accuracy_score(y_train, best_rad.predict(x_train)))\n",
    "print('Test acc: ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "# If you want to compare\n",
    "# for x in range(len(y_pred)):\n",
    "#    print(list(y_pred)[x], list(y_test)[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking part in the challenge\n",
    "\n",
    "Kaggle provides a second dataset. This dataset misses a label. We will try to compute those labels here and store them to a .csv which is formatted in a way Kaggle expects us to if we want to take part in the challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= []\n",
    "_currentId = 892\n",
    "\n",
    "y_pred=best_rad.predict(x_predict)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    result.append({'PassengerId': _currentId,'Survived': list(y_pred)[i]})\n",
    "    _currentId = _currentId + 1\n",
    "\n",
    "resultDf = pd.DataFrame(result)\n",
    "resultDf.to_csv('evaluation_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
